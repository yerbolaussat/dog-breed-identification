{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_tensors_original = np.load(open('train_tensors_original.npy'))\n",
    "test_tensors_original = np.load(open('test_tensors_original.npy'))\n",
    "valid_tensors_original = np.load(open('valid_tensors_original.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# create and configure augmented image generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "    \n",
    "# fit augmented image generator on data\n",
    "train_generator = train_datagen.flow(train_tensors_original, train_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "validation_generator = valid_datagen.flow(valid_tensors_original, valid_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "base_model = keras.applications.ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(133, activation='softmax')(x)\n",
    "ResNet50_model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, None, None, 2 0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 133)          272517      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,860,229\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "ResNet50_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "ResNet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8023 - acc: 0.7676Epoch 00001: val_loss improved from inf to 1.13579, saving model to saved_models/weights.best_resnet_augmented.hdf5\n",
      "418/417 [==============================] - 125s 300ms/step - loss: 0.8037 - acc: 0.7662 - val_loss: 1.1358 - val_acc: 0.7174\n",
      "Epoch 2/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8079 - acc: 0.7695Epoch 00002: val_loss did not improve\n",
      "418/417 [==============================] - 124s 298ms/step - loss: 0.8046 - acc: 0.7696 - val_loss: 1.2524 - val_acc: 0.6719\n",
      "Epoch 3/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7253 - acc: 0.7823Epoch 00003: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7271 - acc: 0.7823 - val_loss: 1.2191 - val_acc: 0.6946\n",
      "Epoch 4/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7649 - acc: 0.7852Epoch 00004: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7690 - acc: 0.7833 - val_loss: 1.1948 - val_acc: 0.7102\n",
      "Epoch 5/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7671 - acc: 0.7847Epoch 00005: val_loss did not improve\n",
      "418/417 [==============================] - 125s 298ms/step - loss: 0.7664 - acc: 0.7847 - val_loss: 1.2403 - val_acc: 0.6994\n",
      "Epoch 6/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7783 - acc: 0.7790Epoch 00006: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7755 - acc: 0.7799 - val_loss: 1.3201 - val_acc: 0.6982\n",
      "Epoch 7/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7743 - acc: 0.7859Epoch 00007: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7695 - acc: 0.7871 - val_loss: 1.3532 - val_acc: 0.6754\n",
      "Epoch 8/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7554 - acc: 0.7942Epoch 00008: val_loss did not improve\n",
      "418/417 [==============================] - 125s 298ms/step - loss: 0.7577 - acc: 0.7943 - val_loss: 1.3060 - val_acc: 0.6934\n",
      "Epoch 9/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7547 - acc: 0.7922Epoch 00009: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7605 - acc: 0.7912 - val_loss: 1.1944 - val_acc: 0.7186\n",
      "Epoch 10/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7518 - acc: 0.7936Epoch 00010: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7551 - acc: 0.7929 - val_loss: 1.2820 - val_acc: 0.7078\n",
      "Epoch 11/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7250 - acc: 0.8048Epoch 00011: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7236 - acc: 0.8052 - val_loss: 1.3162 - val_acc: 0.7150\n",
      "Epoch 12/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7234 - acc: 0.8033Epoch 00012: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7246 - acc: 0.8031 - val_loss: 1.2689 - val_acc: 0.7054\n",
      "Epoch 13/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7183 - acc: 0.8077Epoch 00013: val_loss improved from 1.13579 to 1.13179, saving model to saved_models/weights.best_resnet_augmented.hdf5\n",
      "418/417 [==============================] - 124s 296ms/step - loss: 0.7156 - acc: 0.8080 - val_loss: 1.1318 - val_acc: 0.7437\n",
      "Epoch 14/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7636 - acc: 0.7930Epoch 00014: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7639 - acc: 0.7929 - val_loss: 1.2819 - val_acc: 0.7222\n",
      "Epoch 15/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7173 - acc: 0.8072Epoch 00015: val_loss did not improve\n",
      "418/417 [==============================] - 123s 295ms/step - loss: 0.7195 - acc: 0.8058 - val_loss: 1.3134 - val_acc: 0.7353\n",
      "Epoch 16/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7235 - acc: 0.8101Epoch 00016: val_loss did not improve\n",
      "418/417 [==============================] - 123s 295ms/step - loss: 0.7267 - acc: 0.8104 - val_loss: 1.2904 - val_acc: 0.7042\n",
      "Epoch 17/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7460 - acc: 0.8023Epoch 00017: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7471 - acc: 0.8024 - val_loss: 1.4266 - val_acc: 0.6958\n",
      "Epoch 18/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7160 - acc: 0.8047Epoch 00018: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7201 - acc: 0.8042 - val_loss: 1.3977 - val_acc: 0.7150\n",
      "Epoch 19/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7306 - acc: 0.8096Epoch 00019: val_loss did not improve\n",
      "418/417 [==============================] - 125s 298ms/step - loss: 0.7255 - acc: 0.8103 - val_loss: 1.2989 - val_acc: 0.7126\n",
      "Epoch 20/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7087 - acc: 0.8178Epoch 00020: val_loss did not improve\n",
      "418/417 [==============================] - 123s 295ms/step - loss: 0.7049 - acc: 0.8186 - val_loss: 1.3805 - val_acc: 0.7042\n",
      "Epoch 21/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7257 - acc: 0.8101Epoch 00021: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7281 - acc: 0.8104 - val_loss: 1.3225 - val_acc: 0.7257\n",
      "Epoch 22/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.6964 - acc: 0.8190Epoch 00022: val_loss did not improve\n",
      "418/417 [==============================] - 125s 298ms/step - loss: 0.7013 - acc: 0.8183 - val_loss: 1.3192 - val_acc: 0.7030\n",
      "Epoch 23/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.6902 - acc: 0.8188Epoch 00023: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.6897 - acc: 0.8185 - val_loss: 1.3456 - val_acc: 0.7150\n",
      "Epoch 24/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7082 - acc: 0.8187Epoch 00024: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7075 - acc: 0.8189 - val_loss: 1.4019 - val_acc: 0.6898\n",
      "Epoch 25/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7472 - acc: 0.8114Epoch 00025: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7481 - acc: 0.8121 - val_loss: 1.4466 - val_acc: 0.7066\n",
      "Epoch 26/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7050 - acc: 0.8229Epoch 00026: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7058 - acc: 0.8222 - val_loss: 1.4285 - val_acc: 0.7222\n",
      "Epoch 27/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7026 - acc: 0.8232Epoch 00027: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.6981 - acc: 0.8243 - val_loss: 1.3064 - val_acc: 0.7425\n",
      "Epoch 28/40\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7015 - acc: 0.8214Epoch 00028: val_loss did not improve\n",
      "418/417 [==============================] - 125s 299ms/step - loss: 0.7064 - acc: 0.8213 - val_loss: 1.5408 - val_acc: 0.7102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31037a7c10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING WITH DATA AUGMENTATION (need to recompile the model before running)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best_resnet_augmented.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Using Image Augmentation\n",
    "ResNet50_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_tensors_original.shape[0] // batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=valid_tensors_original.shape[0] // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, EarlyStopping(min_delta=1e-7, patience=15)], verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model weights with the best validation loss.\n",
    "ResNet50_model.load_weights('saved_models/weights.best_resnet_augmented.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "test_tensors_resnet_preprocessed = preprocess_input(test_tensors_original)\n",
    "valid_tensors_resnet_preprocessed = preprocess_input(valid_tensors_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 75.0000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "ResNet50_predictions = [np.argmax(ResNet50_model.predict(np.expand_dims(feature, axis=0))) for feature in test_tensors_resnet_preprocessed]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(ResNet50_predictions)==np.argmax(test_targets, axis=1))/len(ResNet50_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.2455%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "ResNet50_predictions = [np.argmax(ResNet50_model.predict(np.expand_dims(feature, axis=0))) for feature in valid_tensors_resnet_preprocessed]\n",
    "\n",
    "# report test accuracy\n",
    "valid_accuracy = 100.0*np.sum(np.array(ResNet50_predictions)==np.argmax(valid_targets, axis=1))/len(ResNet50_predictions)\n",
    "print('Test accuracy: %.4f%%' % valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# create and configure augmented image generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "    \n",
    "# fit augmented image generator on data\n",
    "train_generator = train_datagen.flow(train_tensors_original, train_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "validation_generator = valid_datagen.flow(valid_tensors_original, valid_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "base_model = keras.applications.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(133, activation='softmax')(x)\n",
    "inception_model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 6 0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_62[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_69[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_90[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "                                                                 activation_98[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_110[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_121[0][0]             \n",
      "                                                                 activation_125[0][0]             \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_128[0][0]             \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_126[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_137[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_141[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_135[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 133)          272517      dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,075,301\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "inception_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.3806 - acc: 0.2635Epoch 00001: val_loss improved from inf to 1.97335, saving model to saved_models/weights.best_inception_augmented.hdf5\n",
      "418/417 [==============================] - 119s 284ms/step - loss: 3.3745 - acc: 0.2637 - val_loss: 1.9733 - val_acc: 0.5078\n",
      "Epoch 2/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.1907 - acc: 0.4437Epoch 00002: val_loss improved from 1.97335 to 1.78038, saving model to saved_models/weights.best_inception_augmented.hdf5\n",
      "418/417 [==============================] - 103s 247ms/step - loss: 2.1896 - acc: 0.4445 - val_loss: 1.7804 - val_acc: 0.5365\n",
      "Epoch 3/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.9667 - acc: 0.4991Epoch 00003: val_loss improved from 1.78038 to 1.73221, saving model to saved_models/weights.best_inception_augmented.hdf5\n",
      "418/417 [==============================] - 103s 247ms/step - loss: 1.9694 - acc: 0.4979 - val_loss: 1.7322 - val_acc: 0.5485\n",
      "Epoch 4/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.8488 - acc: 0.5206Epoch 00004: val_loss improved from 1.73221 to 1.67533, saving model to saved_models/weights.best_inception_augmented.hdf5\n",
      "418/417 [==============================] - 103s 247ms/step - loss: 1.8517 - acc: 0.5195 - val_loss: 1.6753 - val_acc: 0.5725\n",
      "Epoch 5/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.7735 - acc: 0.5377Epoch 00005: val_loss improved from 1.67533 to 1.64435, saving model to saved_models/weights.best_inception_augmented.hdf5\n",
      "418/417 [==============================] - 103s 247ms/step - loss: 1.7734 - acc: 0.5376 - val_loss: 1.6443 - val_acc: 0.5784\n",
      "Epoch 6/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.7596 - acc: 0.5454Epoch 00006: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.7573 - acc: 0.5461 - val_loss: 1.6614 - val_acc: 0.5713\n",
      "Epoch 7/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.7114 - acc: 0.5529Epoch 00007: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.7113 - acc: 0.5533 - val_loss: 1.6525 - val_acc: 0.5892\n",
      "Epoch 8/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6885 - acc: 0.5625Epoch 00008: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6825 - acc: 0.5634 - val_loss: 1.6872 - val_acc: 0.5856\n",
      "Epoch 9/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6669 - acc: 0.5696Epoch 00009: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6670 - acc: 0.5695 - val_loss: 1.7347 - val_acc: 0.5868\n",
      "Epoch 10/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6550 - acc: 0.5714Epoch 00010: val_loss improved from 1.64435 to 1.55892, saving model to saved_models/weights.best_inception_augmented.hdf5\n",
      "418/417 [==============================] - 103s 247ms/step - loss: 1.6495 - acc: 0.5728 - val_loss: 1.5589 - val_acc: 0.5988\n",
      "Epoch 11/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6496 - acc: 0.5747Epoch 00011: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6475 - acc: 0.5746 - val_loss: 1.6396 - val_acc: 0.5832\n",
      "Epoch 12/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6301 - acc: 0.5820Epoch 00012: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6264 - acc: 0.5821 - val_loss: 1.6688 - val_acc: 0.5868\n",
      "Epoch 13/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6233 - acc: 0.5858Epoch 00013: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6246 - acc: 0.5856 - val_loss: 1.6972 - val_acc: 0.5880\n",
      "Epoch 14/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6206 - acc: 0.5861Epoch 00014: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6132 - acc: 0.5879 - val_loss: 1.5783 - val_acc: 0.6192\n",
      "Epoch 15/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6395 - acc: 0.5775Epoch 00015: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6393 - acc: 0.5777 - val_loss: 1.6448 - val_acc: 0.5976\n",
      "Epoch 16/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5747 - acc: 0.5939Epoch 00016: val_loss improved from 1.55892 to 1.55709, saving model to saved_models/weights.best_inception_augmented.hdf5\n",
      "418/417 [==============================] - 103s 247ms/step - loss: 1.5727 - acc: 0.5945 - val_loss: 1.5571 - val_acc: 0.6036\n",
      "Epoch 17/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5775 - acc: 0.5919Epoch 00017: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5829 - acc: 0.5914 - val_loss: 1.6805 - val_acc: 0.5856\n",
      "Epoch 18/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5983 - acc: 0.5907Epoch 00018: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6012 - acc: 0.5908 - val_loss: 1.7314 - val_acc: 0.6060\n",
      "Epoch 19/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5754 - acc: 0.5975Epoch 00019: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5795 - acc: 0.5963 - val_loss: 1.6594 - val_acc: 0.6012\n",
      "Epoch 20/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6281 - acc: 0.5945Epoch 00020: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6296 - acc: 0.5951 - val_loss: 1.6566 - val_acc: 0.6072\n",
      "Epoch 21/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5551 - acc: 0.6028Epoch 00021: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5566 - acc: 0.6027 - val_loss: 1.6358 - val_acc: 0.6060\n",
      "Epoch 22/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5496 - acc: 0.5986Epoch 00022: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5491 - acc: 0.5985 - val_loss: 1.7446 - val_acc: 0.6024\n",
      "Epoch 23/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6066 - acc: 0.5992Epoch 00023: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6056 - acc: 0.5997 - val_loss: 1.7102 - val_acc: 0.5928\n",
      "Epoch 24/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5586 - acc: 0.5999Epoch 00024: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5622 - acc: 0.5981 - val_loss: 1.6509 - val_acc: 0.6132\n",
      "Epoch 25/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6059 - acc: 0.5959Epoch 00025: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6091 - acc: 0.5949 - val_loss: 1.5732 - val_acc: 0.6072\n",
      "Epoch 26/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5527 - acc: 0.6047Epoch 00026: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5598 - acc: 0.6034 - val_loss: 1.7418 - val_acc: 0.6072\n",
      "Epoch 27/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5818 - acc: 0.6004Epoch 00027: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5797 - acc: 0.6006 - val_loss: 1.7821 - val_acc: 0.5916\n",
      "Epoch 28/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5779 - acc: 0.6007Epoch 00028: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5794 - acc: 0.6012 - val_loss: 1.6898 - val_acc: 0.6000\n",
      "Epoch 29/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5655 - acc: 0.6125Epoch 00029: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5648 - acc: 0.6124 - val_loss: 1.6612 - val_acc: 0.6156\n",
      "Epoch 30/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5874 - acc: 0.6131Epoch 00030: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.5930 - acc: 0.6112 - val_loss: 1.8063 - val_acc: 0.5880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.6345 - acc: 0.6014Epoch 00031: val_loss did not improve\n",
      "418/417 [==============================] - 103s 246ms/step - loss: 1.6350 - acc: 0.6013 - val_loss: 1.7212 - val_acc: 0.6216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30216d7550>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING WITH DATA AUGMENTATION (need to recompile the model before running)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best_inception_augmented.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Using Image Augmentation\n",
    "inception_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_tensors_original.shape[0] // batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=valid_tensors_original.shape[0] // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, EarlyStopping(min_delta=1e-7, patience=15)], verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model weights with the best validation loss.\n",
    "inception_model.load_weights('saved_models/weights.best_inception_augmented.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import preprocess_input\n",
    "test_tensors_inception_preprocessed = preprocess_input(test_tensors_original)\n",
    "valid_tensors_inception_preprocessed = preprocess_input(valid_tensors_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0060%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "inception_predictions = [np.argmax(inception_model.predict(np.expand_dims(feature, axis=0))) for feature in test_tensors_inception_preprocessed]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100.0*np.sum(np.array(inception_predictions)==np.argmax(test_targets, axis=1))/len(inception_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 3.0000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "inception_predictions = [np.argmax(inception_model.predict(np.expand_dims(feature, axis=0))) for feature in valid_tensors_inception_preprocessed]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(inception_predictions)==np.argmax(valid_targets, axis=1))/len(inception_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# create and configure augmented image generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "    \n",
    "# fit augmented image generator on data\n",
    "train_generator = train_datagen.flow(train_tensors_original, train_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "validation_generator = valid_datagen.flow(valid_tensors_original, valid_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "base_model = keras.applications.Xception(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(133, activation='softmax')(x)\n",
    "xception_model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 1 512         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, None, None, 2 32768       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 2 1024        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 7 186368      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 7 2912        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 1 745472      add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 1 4096        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 133)          272517      dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,133,997\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "xception_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.8414 - acc: 0.4318Epoch 00001: val_loss improved from inf to 1.43377, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 152s 363ms/step - loss: 2.8360 - acc: 0.4313 - val_loss: 1.4338 - val_acc: 0.6515\n",
      "Epoch 2/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.5154 - acc: 0.6511Epoch 00002: val_loss improved from 1.43377 to 1.25114, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 1.5125 - acc: 0.6521 - val_loss: 1.2511 - val_acc: 0.6910\n",
      "Epoch 3/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.2974 - acc: 0.6777Epoch 00003: val_loss improved from 1.25114 to 1.14347, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 1.2952 - acc: 0.6790 - val_loss: 1.1435 - val_acc: 0.7066\n",
      "Epoch 4/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.1399 - acc: 0.7078Epoch 00004: val_loss improved from 1.14347 to 1.04484, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 1.1408 - acc: 0.7076 - val_loss: 1.0448 - val_acc: 0.7150\n",
      "Epoch 5/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.0715 - acc: 0.7191Epoch 00005: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 1.0716 - acc: 0.7193 - val_loss: 1.0554 - val_acc: 0.7246\n",
      "Epoch 6/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.9968 - acc: 0.7372Epoch 00006: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.9979 - acc: 0.7365 - val_loss: 1.0569 - val_acc: 0.7126\n",
      "Epoch 7/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.9571 - acc: 0.7420Epoch 00007: val_loss improved from 1.04484 to 1.02175, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.9580 - acc: 0.7424 - val_loss: 1.0217 - val_acc: 0.7317\n",
      "Epoch 8/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.9015 - acc: 0.7509Epoch 00008: val_loss improved from 1.02175 to 1.01682, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.8998 - acc: 0.7512 - val_loss: 1.0168 - val_acc: 0.7210\n",
      "Epoch 9/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8851 - acc: 0.7541Epoch 00009: val_loss improved from 1.01682 to 0.95506, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.8850 - acc: 0.7543 - val_loss: 0.9551 - val_acc: 0.7449\n",
      "Epoch 10/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.7593Epoch 00010: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.8737 - acc: 0.7583 - val_loss: 1.0111 - val_acc: 0.7281\n",
      "Epoch 11/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8624 - acc: 0.7590Epoch 00011: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.8638 - acc: 0.7592 - val_loss: 0.9869 - val_acc: 0.7377\n",
      "Epoch 12/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8283 - acc: 0.7742Epoch 00012: val_loss did not improve\n",
      "418/417 [==============================] - 143s 341ms/step - loss: 0.8261 - acc: 0.7746 - val_loss: 0.9993 - val_acc: 0.7150\n",
      "Epoch 13/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8055 - acc: 0.7710Epoch 00013: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.8093 - acc: 0.7705 - val_loss: 0.9811 - val_acc: 0.7198\n",
      "Epoch 14/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8141 - acc: 0.7709Epoch 00014: val_loss improved from 0.95506 to 0.92376, saving model to saved_models/weights.best_xception_augmented.hdf5\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.8110 - acc: 0.7722 - val_loss: 0.9238 - val_acc: 0.7246\n",
      "Epoch 15/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.8012 - acc: 0.7767Epoch 00015: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.8068 - acc: 0.7750 - val_loss: 0.9711 - val_acc: 0.7425\n",
      "Epoch 16/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7634 - acc: 0.7775Epoch 00016: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7640 - acc: 0.7769 - val_loss: 0.9841 - val_acc: 0.7210\n",
      "Epoch 17/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7761 - acc: 0.7806Epoch 00017: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7814 - acc: 0.7795 - val_loss: 0.9417 - val_acc: 0.7449\n",
      "Epoch 18/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7329 - acc: 0.7918Epoch 00018: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7320 - acc: 0.7917 - val_loss: 1.0139 - val_acc: 0.7186\n",
      "Epoch 19/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7440 - acc: 0.7901Epoch 00019: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7419 - acc: 0.7900 - val_loss: 0.9295 - val_acc: 0.7317\n",
      "Epoch 20/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7383 - acc: 0.7945Epoch 00020: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7372 - acc: 0.7943 - val_loss: 0.9923 - val_acc: 0.7257\n",
      "Epoch 21/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7492 - acc: 0.7886Epoch 00021: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7474 - acc: 0.7888 - val_loss: 0.9566 - val_acc: 0.7365\n",
      "Epoch 22/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7482 - acc: 0.7823Epoch 00022: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7458 - acc: 0.7832 - val_loss: 0.9901 - val_acc: 0.7401\n",
      "Epoch 23/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7476 - acc: 0.7873Epoch 00023: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7479 - acc: 0.7872 - val_loss: 1.0220 - val_acc: 0.7305\n",
      "Epoch 24/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7473 - acc: 0.7879Epoch 00024: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7460 - acc: 0.7875 - val_loss: 0.9956 - val_acc: 0.7401\n",
      "Epoch 25/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7025 - acc: 0.7964Epoch 00025: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7077 - acc: 0.7951 - val_loss: 0.9636 - val_acc: 0.7509\n",
      "Epoch 26/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7216 - acc: 0.7948Epoch 00026: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7215 - acc: 0.7949 - val_loss: 0.9953 - val_acc: 0.7461\n",
      "Epoch 27/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.6976 - acc: 0.7982Epoch 00027: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.6976 - acc: 0.7975 - val_loss: 1.0309 - val_acc: 0.7293\n",
      "Epoch 28/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7032 - acc: 0.8030Epoch 00028: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7008 - acc: 0.8037 - val_loss: 1.0378 - val_acc: 0.7269\n",
      "Epoch 29/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 0.7120 - acc: 0.8032Epoch 00029: val_loss did not improve\n",
      "418/417 [==============================] - 143s 342ms/step - loss: 0.7105 - acc: 0.8042 - val_loss: 1.0080 - val_acc: 0.7413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fe022ed90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING WITH DATA AUGMENTATION (need to recompile the model before running)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best_xception_augmented.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Using Image Augmentation\n",
    "xception_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_tensors_original.shape[0] // batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=valid_tensors_original.shape[0] // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, EarlyStopping(min_delta=1e-7, patience=15)], verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model weights with the best validation loss.\n",
    "xception_model.load_weights('saved_models/weights.best_xception_augmented.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "xception_predictions = [np.argmax(xception_model.predict(np.expand_dims(feature, axis=0))) for feature in test_tensors_original]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100.0*np.sum(np.array(xception_predictions)==np.argmax(test_targets, axis=1))/len(xception_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# create and configure augmented image generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "    \n",
    "# fit augmented image generator on data\n",
    "train_generator = train_datagen.flow(train_tensors_original, train_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "validation_generator = valid_datagen.flow(valid_tensors_original, valid_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "base_model = keras.applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2 * 133,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2 * 133,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(133, activation='softmax')(x)\n",
    "vgg16_model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 266)               136458    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 266)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 266)               71022     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 266)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 133)               35511     \n",
      "=================================================================\n",
      "Total params: 14,957,679\n",
      "Trainable params: 242,991\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg16_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 8.6955 - acc: 0.0107Epoch 00001: val_loss improved from inf to 4.85276, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 153s 365ms/step - loss: 8.6589 - acc: 0.0112 - val_loss: 4.8528 - val_acc: 0.0156\n",
      "Epoch 2/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.8827 - acc: 0.0237Epoch 00002: val_loss improved from 4.85276 to 4.75359, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 146s 348ms/step - loss: 4.8883 - acc: 0.0235 - val_loss: 4.7536 - val_acc: 0.0527\n",
      "Epoch 3/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.7720 - acc: 0.0302Epoch 00003: val_loss improved from 4.75359 to 4.58971, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 4.7699 - acc: 0.0302 - val_loss: 4.5897 - val_acc: 0.0719\n",
      "Epoch 4/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.6471 - acc: 0.0430Epoch 00004: val_loss improved from 4.58971 to 4.42095, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 4.6469 - acc: 0.0429 - val_loss: 4.4210 - val_acc: 0.1138\n",
      "Epoch 5/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.4963 - acc: 0.0548Epoch 00005: val_loss improved from 4.42095 to 4.14579, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 4.4957 - acc: 0.0546 - val_loss: 4.1458 - val_acc: 0.1749\n",
      "Epoch 6/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.3704 - acc: 0.0759Epoch 00006: val_loss improved from 4.14579 to 3.94971, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 146s 348ms/step - loss: 4.3705 - acc: 0.0757 - val_loss: 3.9497 - val_acc: 0.1772\n",
      "Epoch 7/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.2221 - acc: 0.0816Epoch 00007: val_loss improved from 3.94971 to 3.66724, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 4.2260 - acc: 0.0814 - val_loss: 3.6672 - val_acc: 0.2299\n",
      "Epoch 8/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.1345 - acc: 0.0877Epoch 00008: val_loss improved from 3.66724 to 3.51108, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 146s 348ms/step - loss: 4.1336 - acc: 0.0878 - val_loss: 3.5111 - val_acc: 0.2719\n",
      "Epoch 9/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 4.0093 - acc: 0.1019Epoch 00009: val_loss improved from 3.51108 to 3.38566, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 4.0107 - acc: 0.1021 - val_loss: 3.3857 - val_acc: 0.2623\n",
      "Epoch 10/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.8999 - acc: 0.1046Epoch 00010: val_loss improved from 3.38566 to 3.28675, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.8987 - acc: 0.1045 - val_loss: 3.2868 - val_acc: 0.2838\n",
      "Epoch 11/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.8345 - acc: 0.1179Epoch 00011: val_loss improved from 3.28675 to 3.17255, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.8365 - acc: 0.1177 - val_loss: 3.1725 - val_acc: 0.3042\n",
      "Epoch 12/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.7891 - acc: 0.1256Epoch 00012: val_loss improved from 3.17255 to 3.04248, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.7893 - acc: 0.1256 - val_loss: 3.0425 - val_acc: 0.3018\n",
      "Epoch 13/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.6922 - acc: 0.1277Epoch 00013: val_loss improved from 3.04248 to 2.91117, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.6932 - acc: 0.1274 - val_loss: 2.9112 - val_acc: 0.3413\n",
      "Epoch 14/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.6448 - acc: 0.1312Epoch 00014: val_loss improved from 2.91117 to 2.85007, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 146s 348ms/step - loss: 3.6448 - acc: 0.1311 - val_loss: 2.8501 - val_acc: 0.3449\n",
      "Epoch 15/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.6181 - acc: 0.1396Epoch 00015: val_loss improved from 2.85007 to 2.84592, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.6214 - acc: 0.1394 - val_loss: 2.8459 - val_acc: 0.3413\n",
      "Epoch 16/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.5541 - acc: 0.1453Epoch 00016: val_loss improved from 2.84592 to 2.76919, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.5515 - acc: 0.1454 - val_loss: 2.7692 - val_acc: 0.3533\n",
      "Epoch 17/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.4928 - acc: 0.1582Epoch 00017: val_loss improved from 2.76919 to 2.73194, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.4903 - acc: 0.1594 - val_loss: 2.7319 - val_acc: 0.4036\n",
      "Epoch 18/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.4641 - acc: 0.1603Epoch 00018: val_loss improved from 2.73194 to 2.67607, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.4626 - acc: 0.1606 - val_loss: 2.6761 - val_acc: 0.3856\n",
      "Epoch 19/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.4259 - acc: 0.1590Epoch 00019: val_loss improved from 2.67607 to 2.65759, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.4245 - acc: 0.1586 - val_loss: 2.6576 - val_acc: 0.3808\n",
      "Epoch 20/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.4110 - acc: 0.1656Epoch 00020: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.4078 - acc: 0.1661 - val_loss: 2.6744 - val_acc: 0.3868\n",
      "Epoch 21/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.3779 - acc: 0.1711Epoch 00021: val_loss improved from 2.65759 to 2.54478, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.3744 - acc: 0.1716 - val_loss: 2.5448 - val_acc: 0.4024\n",
      "Epoch 22/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.3727 - acc: 0.1755Epoch 00022: val_loss did not improve\n",
      "418/417 [==============================] - 147s 352ms/step - loss: 3.3699 - acc: 0.1762 - val_loss: 2.5646 - val_acc: 0.4204\n",
      "Epoch 23/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.3279 - acc: 0.1770Epoch 00023: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.3257 - acc: 0.1762 - val_loss: 2.6191 - val_acc: 0.4072\n",
      "Epoch 24/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.3438 - acc: 0.1779Epoch 00024: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.3480 - acc: 0.1771 - val_loss: 2.5655 - val_acc: 0.3892\n",
      "Epoch 25/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2989 - acc: 0.1839Epoch 00025: val_loss improved from 2.54478 to 2.50323, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2990 - acc: 0.1833 - val_loss: 2.5032 - val_acc: 0.4323\n",
      "Epoch 26/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2910 - acc: 0.1804Epoch 00026: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2901 - acc: 0.1808 - val_loss: 2.5624 - val_acc: 0.3976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2753 - acc: 0.1836Epoch 00027: val_loss improved from 2.50323 to 2.50300, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 146s 348ms/step - loss: 3.2721 - acc: 0.1845 - val_loss: 2.5030 - val_acc: 0.4096\n",
      "Epoch 28/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2490 - acc: 0.1889Epoch 00028: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2491 - acc: 0.1897 - val_loss: 2.5042 - val_acc: 0.4287\n",
      "Epoch 29/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2829 - acc: 0.1830Epoch 00029: val_loss improved from 2.50300 to 2.46200, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 146s 348ms/step - loss: 3.2796 - acc: 0.1830 - val_loss: 2.4620 - val_acc: 0.4287\n",
      "Epoch 30/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2252 - acc: 0.1952Epoch 00030: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2223 - acc: 0.1954 - val_loss: 2.4953 - val_acc: 0.3856\n",
      "Epoch 31/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2043 - acc: 0.1913Epoch 00031: val_loss improved from 2.46200 to 2.45260, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2046 - acc: 0.1912 - val_loss: 2.4526 - val_acc: 0.4228\n",
      "Epoch 32/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2165 - acc: 0.1935Epoch 00032: val_loss improved from 2.45260 to 2.41869, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2257 - acc: 0.1935 - val_loss: 2.4187 - val_acc: 0.3760\n",
      "Epoch 33/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2349 - acc: 0.1917Epoch 00033: val_loss improved from 2.41869 to 2.41296, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2296 - acc: 0.1926 - val_loss: 2.4130 - val_acc: 0.4251\n",
      "Epoch 34/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2251 - acc: 0.1970Epoch 00034: val_loss improved from 2.41296 to 2.39686, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 147s 352ms/step - loss: 3.2214 - acc: 0.1975 - val_loss: 2.3969 - val_acc: 0.4419\n",
      "Epoch 35/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2025 - acc: 0.2043Epoch 00035: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2058 - acc: 0.2039 - val_loss: 2.4113 - val_acc: 0.4228\n",
      "Epoch 36/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2167 - acc: 0.1958Epoch 00036: val_loss improved from 2.39686 to 2.34042, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2176 - acc: 0.1948 - val_loss: 2.3404 - val_acc: 0.4204\n",
      "Epoch 37/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1852 - acc: 0.2000Epoch 00037: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1825 - acc: 0.1996 - val_loss: 2.3474 - val_acc: 0.4383\n",
      "Epoch 38/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1595 - acc: 0.1997Epoch 00038: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1568 - acc: 0.1999 - val_loss: 2.3591 - val_acc: 0.4084\n",
      "Epoch 39/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.2005 - acc: 0.1974Epoch 00039: val_loss improved from 2.34042 to 2.32069, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.2055 - acc: 0.1967 - val_loss: 2.3207 - val_acc: 0.4299\n",
      "Epoch 40/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1491 - acc: 0.1982Epoch 00040: val_loss improved from 2.32069 to 2.29357, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1528 - acc: 0.1984 - val_loss: 2.2936 - val_acc: 0.4503\n",
      "Epoch 41/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1724 - acc: 0.2066Epoch 00041: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1758 - acc: 0.2061 - val_loss: 2.3541 - val_acc: 0.4383\n",
      "Epoch 42/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1590 - acc: 0.2058Epoch 00042: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1565 - acc: 0.2062 - val_loss: 2.3259 - val_acc: 0.4455\n",
      "Epoch 43/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1822 - acc: 0.2009Epoch 00043: val_loss did not improve\n",
      "418/417 [==============================] - 147s 352ms/step - loss: 3.1823 - acc: 0.2007 - val_loss: 2.3075 - val_acc: 0.4263\n",
      "Epoch 44/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1781 - acc: 0.1986Epoch 00044: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1757 - acc: 0.1997 - val_loss: 2.3198 - val_acc: 0.4443\n",
      "Epoch 45/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1655 - acc: 0.2081Epoch 00045: val_loss did not improve\n",
      "418/417 [==============================] - 147s 352ms/step - loss: 3.1662 - acc: 0.2082 - val_loss: 2.3580 - val_acc: 0.4228\n",
      "Epoch 46/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1568 - acc: 0.2066Epoch 00046: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1577 - acc: 0.2061 - val_loss: 2.3255 - val_acc: 0.4144\n",
      "Epoch 47/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1745 - acc: 0.1991Epoch 00047: val_loss improved from 2.29357 to 2.27956, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1732 - acc: 0.1996 - val_loss: 2.2796 - val_acc: 0.4419\n",
      "Epoch 48/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1540 - acc: 0.1986Epoch 00048: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1538 - acc: 0.1997 - val_loss: 2.3601 - val_acc: 0.4287\n",
      "Epoch 49/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1429 - acc: 0.2030Epoch 00049: val_loss improved from 2.27956 to 2.26011, saving model to saved_models/weights.best_vgg16_augmented.hdf5\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1412 - acc: 0.2037 - val_loss: 2.2601 - val_acc: 0.4575\n",
      "Epoch 50/50\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1419 - acc: 0.2124Epoch 00050: val_loss did not improve\n",
      "418/417 [==============================] - 145s 348ms/step - loss: 3.1486 - acc: 0.2119 - val_loss: 2.2939 - val_acc: 0.4431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fdf46c5d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING WITH DATA AUGMENTATION (need to recompile the model before running)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best_vgg16_augmented.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Using Image Augmentation\n",
    "vgg16_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_tensors_original.shape[0] // batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=valid_tensors_original.shape[0] // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, EarlyStopping(min_delta=1e-7, patience=15)], verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model weights with the best validation loss.\n",
    "vgg16_model.load_weights('saved_models/weights.best_vgg16_augmented.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "test_tensors_vgg16_preprocessed = preprocess_input(test_tensors_original)\n",
    "valid_tensors_vgg16_preprocessed = preprocess_input(valid_tensors_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "vgg16_predictions = [np.argmax(vgg16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_tensors_vgg16_preprocessed]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(vgg16_predictions)==np.argmax(test_targets, axis=1))/len(vgg16_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "batch_size = 19\n",
    "\n",
    "# create and configure augmented image generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "    \n",
    "# fit augmented image generator on data\n",
    "train_generator = train_datagen.flow(train_tensors_original, train_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    shear_range = 0.2, # rnadomly applying shear transformation\n",
    "    zoom_range = 0.2) # randomly zooming inside pictures\n",
    "\n",
    "validation_generator = valid_datagen.flow(valid_tensors_original, valid_targets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 5s 0us/step\n",
      "80150528/80134624 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "base_model = keras.applications.VGG19(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2 * 133,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2 * 133,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(133, activation='softmax')(x)\n",
    "vgg19_model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 266)               136458    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 266)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 266)               71022     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 266)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 133)               35511     \n",
      "=================================================================\n",
      "Total params: 20,267,375\n",
      "Trainable params: 242,991\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg19_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 8.1393 - acc: 0.0131Epoch 00001: val_loss improved from inf to 4.86605, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 219s 623ms/step - loss: 8.1026 - acc: 0.0129 - val_loss: 4.8660 - val_acc: 0.0240\n",
      "Epoch 2/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 4.8852 - acc: 0.0227Epoch 00002: val_loss improved from 4.86605 to 4.79759, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 4.8835 - acc: 0.0227 - val_loss: 4.7976 - val_acc: 0.0587\n",
      "Epoch 3/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 4.7755 - acc: 0.0350Epoch 00003: val_loss improved from 4.79759 to 4.59830, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 4.7738 - acc: 0.0355 - val_loss: 4.5983 - val_acc: 0.0790\n",
      "Epoch 4/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 4.6217 - acc: 0.0530Epoch 00004: val_loss improved from 4.59830 to 4.33324, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 4.6194 - acc: 0.0530 - val_loss: 4.3332 - val_acc: 0.1281\n",
      "Epoch 5/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 4.4993 - acc: 0.0610Epoch 00005: val_loss improved from 4.33324 to 4.12047, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 605ms/step - loss: 4.4986 - acc: 0.0615 - val_loss: 4.1205 - val_acc: 0.1581\n",
      "Epoch 6/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 4.3233 - acc: 0.0769Epoch 00006: val_loss improved from 4.12047 to 3.85172, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 605ms/step - loss: 4.3282 - acc: 0.0766 - val_loss: 3.8517 - val_acc: 0.2024\n",
      "Epoch 7/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 4.2437 - acc: 0.0877Epoch 00007: val_loss improved from 3.85172 to 3.67896, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 4.2473 - acc: 0.0873 - val_loss: 3.6790 - val_acc: 0.2443\n",
      "Epoch 8/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 4.0770 - acc: 0.1032Epoch 00008: val_loss improved from 3.67896 to 3.46229, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 605ms/step - loss: 4.0726 - acc: 0.1038 - val_loss: 3.4623 - val_acc: 0.2719\n",
      "Epoch 9/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.9616 - acc: 0.1049Epoch 00009: val_loss improved from 3.46229 to 3.33022, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.9577 - acc: 0.1049 - val_loss: 3.3302 - val_acc: 0.2707\n",
      "Epoch 10/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.8542 - acc: 0.1248Epoch 00010: val_loss improved from 3.33022 to 3.17145, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.8535 - acc: 0.1240 - val_loss: 3.1715 - val_acc: 0.3210\n",
      "Epoch 11/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.7369 - acc: 0.1408Epoch 00011: val_loss improved from 3.17145 to 2.98226, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.7340 - acc: 0.1406 - val_loss: 2.9823 - val_acc: 0.3329\n",
      "Epoch 12/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.6477 - acc: 0.1469Epoch 00012: val_loss improved from 2.98226 to 2.90879, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.6492 - acc: 0.1455 - val_loss: 2.9088 - val_acc: 0.3629\n",
      "Epoch 13/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.5522 - acc: 0.1557Epoch 00013: val_loss improved from 2.90879 to 2.80799, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.5495 - acc: 0.1572 - val_loss: 2.8080 - val_acc: 0.3880\n",
      "Epoch 14/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.5050 - acc: 0.1629Epoch 00014: val_loss improved from 2.80799 to 2.70951, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.5073 - acc: 0.1623 - val_loss: 2.7095 - val_acc: 0.3545\n",
      "Epoch 15/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.4619 - acc: 0.1683Epoch 00015: val_loss improved from 2.70951 to 2.67503, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.4647 - acc: 0.1682 - val_loss: 2.6750 - val_acc: 0.3737\n",
      "Epoch 16/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.4077 - acc: 0.1771Epoch 00016: val_loss improved from 2.67503 to 2.55466, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.4100 - acc: 0.1775 - val_loss: 2.5547 - val_acc: 0.3964\n",
      "Epoch 17/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.3315 - acc: 0.1779Epoch 00017: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.3334 - acc: 0.1788 - val_loss: 2.5838 - val_acc: 0.3772\n",
      "Epoch 18/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.3203 - acc: 0.1831Epoch 00018: val_loss improved from 2.55466 to 2.54151, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.3200 - acc: 0.1834 - val_loss: 2.5415 - val_acc: 0.4180\n",
      "Epoch 19/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.3009 - acc: 0.1863Epoch 00019: val_loss improved from 2.54151 to 2.46088, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 605ms/step - loss: 3.3036 - acc: 0.1857 - val_loss: 2.4609 - val_acc: 0.4659\n",
      "Epoch 20/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.2450 - acc: 0.1960Epoch 00020: val_loss did not improve\n",
      "352/351 [==============================] - 212s 604ms/step - loss: 3.2458 - acc: 0.1959 - val_loss: 2.4821 - val_acc: 0.4263\n",
      "Epoch 21/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.2651 - acc: 0.1917Epoch 00021: val_loss improved from 2.46088 to 2.39588, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.2654 - acc: 0.1910 - val_loss: 2.3959 - val_acc: 0.4395\n",
      "Epoch 22/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.1991 - acc: 0.1987Epoch 00022: val_loss improved from 2.39588 to 2.35659, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.2008 - acc: 0.1980 - val_loss: 2.3566 - val_acc: 0.4479\n",
      "Epoch 23/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.1547 - acc: 0.1995Epoch 00023: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.1556 - acc: 0.1999 - val_loss: 2.3569 - val_acc: 0.4467\n",
      "Epoch 24/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.1962 - acc: 0.2050Epoch 00024: val_loss improved from 2.35659 to 2.35114, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.1925 - acc: 0.2053 - val_loss: 2.3511 - val_acc: 0.4575\n",
      "Epoch 25/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0977 - acc: 0.2262Epoch 00025: val_loss improved from 2.35114 to 2.31585, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.1061 - acc: 0.2252 - val_loss: 2.3159 - val_acc: 0.4455\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/351 [============================>.] - ETA: 0s - loss: 3.1367 - acc: 0.2139Epoch 00026: val_loss improved from 2.31585 to 2.29301, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.1374 - acc: 0.2133 - val_loss: 2.2930 - val_acc: 0.4443\n",
      "Epoch 27/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.1200 - acc: 0.2115Epoch 00027: val_loss improved from 2.29301 to 2.28150, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.1156 - acc: 0.2124 - val_loss: 2.2815 - val_acc: 0.4575\n",
      "Epoch 28/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0942 - acc: 0.2157Epoch 00028: val_loss improved from 2.28150 to 2.26787, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0898 - acc: 0.2171 - val_loss: 2.2679 - val_acc: 0.4599\n",
      "Epoch 29/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.1005 - acc: 0.2202Epoch 00029: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0914 - acc: 0.2231 - val_loss: 2.2783 - val_acc: 0.4539\n",
      "Epoch 30/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0985 - acc: 0.2147Epoch 00030: val_loss improved from 2.26787 to 2.22901, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0969 - acc: 0.2146 - val_loss: 2.2290 - val_acc: 0.4754\n",
      "Epoch 31/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0834 - acc: 0.2224Epoch 00031: val_loss improved from 2.22901 to 2.22314, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0832 - acc: 0.2216 - val_loss: 2.2231 - val_acc: 0.4611\n",
      "Epoch 32/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0621 - acc: 0.2230Epoch 00032: val_loss improved from 2.22314 to 2.22257, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0620 - acc: 0.2235 - val_loss: 2.2226 - val_acc: 0.4623\n",
      "Epoch 33/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0547 - acc: 0.2292Epoch 00033: val_loss improved from 2.22257 to 2.19478, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0504 - acc: 0.2304 - val_loss: 2.1948 - val_acc: 0.4683\n",
      "Epoch 34/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0439 - acc: 0.2336Epoch 00034: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0504 - acc: 0.2334 - val_loss: 2.2223 - val_acc: 0.4754\n",
      "Epoch 35/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0345 - acc: 0.2250Epoch 00035: val_loss improved from 2.19478 to 2.16318, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0319 - acc: 0.2252 - val_loss: 2.1632 - val_acc: 0.4731\n",
      "Epoch 36/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0237 - acc: 0.2336Epoch 00036: val_loss improved from 2.16318 to 2.12732, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0223 - acc: 0.2336 - val_loss: 2.1273 - val_acc: 0.4850\n",
      "Epoch 37/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0336 - acc: 0.2343Epoch 00037: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0321 - acc: 0.2331 - val_loss: 2.1463 - val_acc: 0.4850\n",
      "Epoch 38/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0082 - acc: 0.2357Epoch 00038: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0112 - acc: 0.2339 - val_loss: 2.1427 - val_acc: 0.4910\n",
      "Epoch 39/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9761 - acc: 0.2395Epoch 00039: val_loss improved from 2.12732 to 2.11205, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9789 - acc: 0.2392 - val_loss: 2.1121 - val_acc: 0.4695\n",
      "Epoch 40/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9772 - acc: 0.2389Epoch 00040: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9771 - acc: 0.2383 - val_loss: 2.2118 - val_acc: 0.4659\n",
      "Epoch 41/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9693 - acc: 0.2470Epoch 00041: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9670 - acc: 0.2481 - val_loss: 2.1659 - val_acc: 0.4898\n",
      "Epoch 42/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9761 - acc: 0.2397Epoch 00042: val_loss improved from 2.11205 to 2.10338, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9767 - acc: 0.2397 - val_loss: 2.1034 - val_acc: 0.4790\n",
      "Epoch 43/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9651 - acc: 0.2385Epoch 00043: val_loss improved from 2.10338 to 2.07316, saving model to saved_models/weights.best_vgg19_augmented.hdf5\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9658 - acc: 0.2388 - val_loss: 2.0732 - val_acc: 0.4910\n",
      "Epoch 44/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 3.0231 - acc: 0.2377Epoch 00044: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 3.0165 - acc: 0.2379 - val_loss: 2.1983 - val_acc: 0.4443\n",
      "Epoch 45/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9986 - acc: 0.2473Epoch 00045: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9997 - acc: 0.2478 - val_loss: 2.1097 - val_acc: 0.4838\n",
      "Epoch 46/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9652 - acc: 0.2439Epoch 00046: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9669 - acc: 0.2438 - val_loss: 2.1365 - val_acc: 0.4790\n",
      "Epoch 47/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9774 - acc: 0.2464Epoch 00047: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9736 - acc: 0.2478 - val_loss: 2.1020 - val_acc: 0.4982\n",
      "Epoch 48/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9732 - acc: 0.2481Epoch 00048: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9760 - acc: 0.2483 - val_loss: 2.1503 - val_acc: 0.4467\n",
      "Epoch 49/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9389 - acc: 0.2535Epoch 00049: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9416 - acc: 0.2530 - val_loss: 2.1177 - val_acc: 0.4707\n",
      "Epoch 50/50\n",
      "350/351 [============================>.] - ETA: 0s - loss: 2.9470 - acc: 0.2530Epoch 00050: val_loss did not improve\n",
      "352/351 [==============================] - 213s 604ms/step - loss: 2.9473 - acc: 0.2522 - val_loss: 2.1148 - val_acc: 0.4635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fc043d310>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING WITH DATA AUGMENTATION (need to recompile the model before running)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best_vgg19_augmented.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Using Image Augmentation\n",
    "vgg19_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_tensors_original.shape[0] // batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=valid_tensors_original.shape[0] // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[checkpointer, EarlyStopping(min_delta=1e-7, patience=15)], verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model weights with the best validation loss.\n",
    "vgg19_model.load_weights('saved_models/weights.best_vgg19_augmented.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import preprocess_input\n",
    "test_tensors_vgg19_preprocessed = preprocess_input(test_tensors_original)\n",
    "valid_tensors_vgg19_preprocessed = preprocess_input(valid_tensors_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "vgg19_predictions = [np.argmax(vgg19_model.predict(np.expand_dims(feature, axis=0))) for feature in test_tensors_vgg19_preprocessed]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(vgg19_predictions)==np.argmax(test_targets, axis=1))/len(vgg19_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
